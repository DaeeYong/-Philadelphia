{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import csv\n",
    "from dragon import dragonV\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data_parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/Users/ivory/Documents/github/Philadelphia/real_final_data/'\n",
    "subject_list = ['pp01', 'pp02', 'pp009', 'pp085', 'pp086', 'pp087', 'pp088', 'pp089'] \n",
    "#front, rear 2가지 존재. 파일명 format : {gait_catergory}_{front || rear}.xlsx\n",
    "gait_category_list = ['gait1', 'gait2', 'fast', 'preferred', 'reaction', 'slow', 'stroop', 'turn']\n",
    "seleted_openpose_joint_idx_list = [8, 9, 10, 11, 12, 13, 14, 19, 20, 21, 22, 23, 24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xlsx -> nomalize -> lower joint -> frame & gt pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subject_data = []\n",
    "for each_subject in subject_list:\n",
    "    #root/ppxx/\n",
    "    each_subject_path = root_path + each_subject + '/'\n",
    "    files = os.listdir(each_subject_path)\n",
    "\n",
    "    ###xlsx_list###\n",
    "    excel_name_list = [file for file in files if file.endswith('.xlsx')]\n",
    "    \n",
    "    ###gt_list####\n",
    "    tmp = os.listdir(each_subject_path + 'gt/')\n",
    "    gt_name_list = [file for file in tmp if file.endswith('.npy')]\n",
    "\n",
    "    #ppxx/{each_excel_name}\n",
    "    #하나의 엑셀 파일에 대한 반복문\n",
    "    for each_excel in excel_name_list:\n",
    "        ##xlsx -> list##\n",
    "        frame_data_list = dragonV.xlsx2data(each_subject_path + each_excel)\n",
    "        #print(f'{each_excel} : {len(frame_data_list[0])}')\n",
    "        ##list -> normalize##\n",
    "        norm_frame_data_list = dragonV.nomalize_data(frame_data_list)\n",
    "        #print(f'{each_subject}->{each_excel} : {len(norm_frame_data_list[0])}')\n",
    "\n",
    "        ##noramlize -> select lower joint pos##\n",
    "        selected_norm_frame_data_list = dragonV.get_selected_joint_pos_frame_list(norm_frame_data_list, seleted_openpose_joint_idx_list)\n",
    "        #print(f'{each_subject}->{each_excel} : {len(selected_norm_frame_data_list[0])}')\n",
    "        \n",
    "        ## 여기까진 왔음...\n",
    "        ##frame data : gt pair##\n",
    "        for each_gt in gt_name_list:\n",
    "            #확장자명 제거\n",
    "            each_gt_name = each_gt[:-4]\n",
    "            if each_gt_name in each_excel:\n",
    "                #print(f'{each_subject}:{each_excel} -> {each_gt_name}')\n",
    "                right_gt_np = np.load(each_subject_path + '/gt/' + each_gt)\n",
    "                right_gt_list = right_gt_np.tolist()\n",
    "\n",
    "                data_gt_pair_list = dragonV.make_dataAndGtPair(selected_norm_frame_data_list, right_gt_list)\n",
    "                all_subject_data.append(data_gt_pair_list)\n",
    "            else:\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = len(all_subject_data)\n",
    "d2 = len(all_subject_data[0])\n",
    "d3 = len(all_subject_data[0][0])\n",
    "d4_0 = len(all_subject_data[0][0][0])\n",
    "d4_1 = len(all_subject_data[0][0][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_num : 73\n",
      "frame_num : 1063\n",
      "features || label : 2\n",
      "d4_0 : 26\n",
      "d4_1 : 4\n"
     ]
    }
   ],
   "source": [
    "print('video_num :',d1)\n",
    "print('frame_num :',d2)\n",
    "print('features || label :',d3)\n",
    "print('d4_0 :',d4_0)\n",
    "print('d4_1 :',d4_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## list -> torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98548271, 0.92060491, 0.98759102, 0.96146204, 0.9881226 ,\n",
       "       0.9740866 , 0.99484523, 0.98557527, 0.81086829, 0.91704873,\n",
       "       0.70520791, 0.97594994, 0.71989963, 0.9997064 , 0.62189694,\n",
       "       0.89097924, 0.9188043 , 0.9825343 , 0.73717281, 0.98529396,\n",
       "       0.99225403, 0.97184447, 0.98237504, 0.9717276 , 0.99244709,\n",
       "       0.97882186])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_num = 0\n",
    "frame_num = 0\n",
    "features_labels = 0\n",
    "np.array(all_subject_data[video_num][frame_num][features_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[\n",
    "    [\n",
    "        [features],\n",
    "        [features],\n",
    "        ......... ,\n",
    "        [features]\n",
    "    ],\n",
    "    [\n",
    "        [features],\n",
    "        [features],\n",
    "        ......... ,\n",
    "        [features]\n",
    "    ],\n",
    "    [\n",
    "        [features],\n",
    "        [features],\n",
    "        ......... ,\n",
    "        [features]\n",
    "    ],    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1705757532.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[118], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    ........,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "[\n",
    "    [labels],\n",
    "    [labels],\n",
    "    [labels],\n",
    "    [labels],\n",
    "    ........,\n",
    "    [labels]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = all_subject_data[0]\n",
    "t_len = len(t)\n",
    "t_frame_list = []\n",
    "t_label_list = []\n",
    "for i in range(0, t_len):\n",
    "    t_frame_list.append(t[i][0])\n",
    "    t_label_list.append(t[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_len : 1063\n",
      "label_len : 1063\n"
     ]
    }
   ],
   "source": [
    "print(f'frame_len : {len(t_frame_list)}')\n",
    "print(f'label_len : {len(t_label_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98548271, 0.92060491, 0.98759102, 0.96146204, 0.9881226 ,\n",
       "        0.9740866 , 0.99484523, 0.98557527, 0.81086829, 0.91704873,\n",
       "        0.70520791, 0.97594994, 0.71989963, 0.9997064 , 0.62189694,\n",
       "        0.89097924, 0.9188043 , 0.9825343 , 0.73717281, 0.98529396,\n",
       "        0.99225403, 0.97184447, 0.98237504, 0.9717276 , 0.99244709,\n",
       "        0.97882186],\n",
       "       [0.98563035, 0.95936408, 0.98771679, 0.96165813, 0.98816563,\n",
       "        0.97402027, 0.99489721, 0.9855716 , 0.81091135, 0.91741665,\n",
       "        0.70516431, 0.95371315, 0.71994492, 0.99957975, 0.63497453,\n",
       "        0.90563174, 0.92120914, 0.98594924, 0.73730697, 0.98518937,\n",
       "        0.98968955, 0.97188273, 0.97990497, 0.97173477, 0.99492728,\n",
       "        0.97883029],\n",
       "       [0.98572877, 0.92044172, 0.98767487, 0.9613836 , 0.9881226 ,\n",
       "        0.97385442, 0.99487122, 0.98558631, 0.82275091, 0.91665252,\n",
       "        0.70520791, 0.95289556, 0.71999022, 0.99959702, 0.63502042,\n",
       "        0.90579095, 0.92121776, 0.9859887 , 0.73735169, 0.98525213,\n",
       "        0.99218401, 0.97179785, 0.97994785, 0.97167499, 0.99245573,\n",
       "        0.97885076],\n",
       "       [0.98567956, 0.92074091, 0.98775871, 0.96161891, 0.98807956,\n",
       "        0.97416953, 0.9949232 , 0.98557527, 0.82275091, 0.91686478,\n",
       "        0.7052515 , 0.95313031, 0.72003551, 0.99982154, 0.63483687,\n",
       "        0.90561051, 0.91883878, 0.98597316, 0.73748586, 0.99993724,\n",
       "        0.98961078, 0.97183013, 0.97985351, 0.97166662, 0.99496185,\n",
       "        0.97882066],\n",
       "       [0.98563035, 0.92016972, 0.98767487, 0.96106986, 0.98816563,\n",
       "        0.97426903, 0.99488854, 0.98562921, 0.82270786, 0.91646856,\n",
       "        0.70516431, 0.9531465 , 0.71999022, 0.99971216, 0.63488276,\n",
       "        0.90556275, 0.91883878, 0.98594805, 0.73739641, 0.99979081,\n",
       "        0.98961953, 0.97175959, 0.97987066, 0.96836331, 0.99491864,\n",
       "        0.97885798],\n",
       "       [0.98563035, 0.92019692, 0.98767487, 0.9611483 , 0.9881226 ,\n",
       "        0.97388759, 0.99487988, 0.98565005, 0.81099745, 0.91676572,\n",
       "        0.70512072, 0.95289556, 0.72008081, 0.99943008, 0.63502042,\n",
       "        0.89096863, 0.92122638, 0.9825355 , 0.7375753 , 0.98493311,\n",
       "        0.98961078, 0.96839632, 0.97987924, 0.96827723, 0.99490135,\n",
       "        0.97889411],\n",
       "       [0.98567956, 0.95951367, 0.98771679, 0.96173656, 0.9881226 ,\n",
       "        0.95154817, 0.99490587, 0.98565618, 0.8110405 , 0.95790174,\n",
       "        0.70520791, 0.95313841, 0.72017139, 0.99904437, 0.63515808,\n",
       "        0.90568481, 0.92125224, 0.98254387, 0.73762002, 0.96987145,\n",
       "        0.98965454, 0.97176198, 0.97992212, 0.96838364, 0.99492728,\n",
       "        0.97890374],\n",
       "       [0.9854335 , 0.96061525, 0.98746526, 0.96282159, 0.98807956,\n",
       "        0.97489925, 0.99490587, 0.98910208, 0.81091135, 0.95889229,\n",
       "        0.69348074, 0.9529927 , 0.72008081, 0.9988947 , 0.63520396,\n",
       "        0.9055256 , 0.92125224, 0.98248169, 0.7375753 , 0.96957336,\n",
       "        0.99219277, 0.9717548 , 0.97995643, 0.96839798, 0.99491864,\n",
       "        0.97891458],\n",
       "       [0.98567956, 0.96047925, 0.98775871, 0.9627693 , 0.9881226 ,\n",
       "        0.97410319, 0.99495785, 0.98559366, 0.82270786, 0.95851022,\n",
       "        0.69343715, 0.95279032, 0.72003551, 0.99911921, 0.63524985,\n",
       "        0.89098455, 0.92125224, 0.98249604, 0.73748586, 0.98461933,\n",
       "        0.99221902, 0.97179306, 0.97996501, 0.97165586, 0.99497049,\n",
       "        0.97882306]])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(t_frame_list[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(t_frame_list[0]))\n",
    "print(len(t_label_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "1063\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "print(len(all_subject_data))\n",
    "print(len(all_subject_data[0]))\n",
    "print(len(all_subject_data[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timesteps이 9라서 앞, 뒤로 레이블 데이터 4개씩 버려야 함.\n",
    "'''\n",
    "each_video : frame_num x (features || label) x (26 || 4)\n",
    "'''\n",
    "trimmed_data = []\n",
    "trimmed_label = []\n",
    "\n",
    "for each_video in all_subject_data:\n",
    "    #각 비디오의 전체 프레임 길이\n",
    "    video_len = len(each_video)\n",
    "    #frame_number x each_element(26)\n",
    "    total_frame_features_list = []\n",
    "    #frame_number x each_label(4)\n",
    "    total_frame_label_list = []\n",
    "    \n",
    "    #각각의 비디오에서 frame_data와 frame별 label 값 추출\n",
    "    for i in range(0, video_len):\n",
    "        total_frame_features_list.append(each_video[i][0])\n",
    "        total_frame_label_list.append(each_video[i][1])\n",
    "\n",
    "    #timesteps 수만큼 frame data 묶기.\n",
    "    for idx in range(0, len(total_frame_features_list) - 8):\n",
    "        trimmed_data.append(total_frame_features_list[idx:idx+9])\n",
    "    \n",
    "    del total_frame_label_list[0:4]\n",
    "    del total_frame_label_list[-4:]\n",
    "    \n",
    "    for label in total_frame_label_list:\n",
    "        trimmed_label.append(label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_num : 45834\n",
      "timesteps : 9\n",
      "input_size : 26\n",
      "\n",
      "\n",
      "sample_num : 45834\n",
      "label_size : 4\n"
     ]
    }
   ],
   "source": [
    "####data info###\n",
    "print(f'sample_num : {len(trimmed_data)}')\n",
    "print(f'timesteps : {len(trimmed_data[0])}')\n",
    "print(f'input_size : {len(trimmed_data[0][0])}')\n",
    "##########\n",
    "\n",
    "print('\\n')\n",
    "###label###\n",
    "print(f'sample_num : {len(trimmed_label)}')\n",
    "print(f'label_size : {len(trimmed_label[0])}')\n",
    "\n",
    "########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# data 저장된 곳\\ntrimmed_data : list\\ntrimmed_label : list\\n\\ntrimmed_data : sample_size x timesteps(9) x input_size(26)\\ntrimmed_label : sample_size x label_size(4)\\n'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# data 저장된 곳\n",
    "trimmed_data : list\n",
    "trimmed_label : list\n",
    "\n",
    "trimmed_data : sample_size x timesteps(9) x input_size(26)\n",
    "trimmed_label : sample_size x label_size(4)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data_preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputs, _status = cell(output)<br>\n",
    "\n",
    "(모든 timesteps에 대한 결과)<br>\n",
    "outputs -> [bactch x timesteps x output]<br><br>\n",
    "(마지막 timestpes에 대한 결과)<br>\n",
    "_status -> [1 x batch x output]<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_tensor = torch.tensor(trimmed_data, dtype=torch.float32)\n",
    "label_tensor = torch.tensor(trimmed_label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([45834, 9, 26])\n",
      "torch.Size([45834, 4])\n"
     ]
    }
   ],
   "source": [
    "print(input_data_tensor.shape)\n",
    "print(label_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyper-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 26\n",
    "output_size = 4\n",
    "hidden_size = 128\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(input_data_tensor, label_tensor)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9855, 0.9206, 0.9876, 0.9615, 0.9881, 0.9741, 0.9948, 0.9856, 0.8109,\n",
      "         0.9170, 0.7052, 0.9759, 0.7199, 0.9997, 0.6219, 0.8910, 0.9188, 0.9825,\n",
      "         0.7372, 0.9853, 0.9923, 0.9718, 0.9824, 0.9717, 0.9924, 0.9788],\n",
      "        [0.9856, 0.9594, 0.9877, 0.9617, 0.9882, 0.9740, 0.9949, 0.9856, 0.8109,\n",
      "         0.9174, 0.7052, 0.9537, 0.7199, 0.9996, 0.6350, 0.9056, 0.9212, 0.9859,\n",
      "         0.7373, 0.9852, 0.9897, 0.9719, 0.9799, 0.9717, 0.9949, 0.9788],\n",
      "        [0.9857, 0.9204, 0.9877, 0.9614, 0.9881, 0.9739, 0.9949, 0.9856, 0.8228,\n",
      "         0.9167, 0.7052, 0.9529, 0.7200, 0.9996, 0.6350, 0.9058, 0.9212, 0.9860,\n",
      "         0.7374, 0.9853, 0.9922, 0.9718, 0.9799, 0.9717, 0.9925, 0.9789],\n",
      "        [0.9857, 0.9207, 0.9878, 0.9616, 0.9881, 0.9742, 0.9949, 0.9856, 0.8228,\n",
      "         0.9169, 0.7053, 0.9531, 0.7200, 0.9998, 0.6348, 0.9056, 0.9188, 0.9860,\n",
      "         0.7375, 0.9999, 0.9896, 0.9718, 0.9799, 0.9717, 0.9950, 0.9788],\n",
      "        [0.9856, 0.9202, 0.9877, 0.9611, 0.9882, 0.9743, 0.9949, 0.9856, 0.8227,\n",
      "         0.9165, 0.7052, 0.9531, 0.7200, 0.9997, 0.6349, 0.9056, 0.9188, 0.9859,\n",
      "         0.7374, 0.9998, 0.9896, 0.9718, 0.9799, 0.9684, 0.9949, 0.9789],\n",
      "        [0.9856, 0.9202, 0.9877, 0.9611, 0.9881, 0.9739, 0.9949, 0.9857, 0.8110,\n",
      "         0.9168, 0.7051, 0.9529, 0.7201, 0.9994, 0.6350, 0.8910, 0.9212, 0.9825,\n",
      "         0.7376, 0.9849, 0.9896, 0.9684, 0.9799, 0.9683, 0.9949, 0.9789],\n",
      "        [0.9857, 0.9595, 0.9877, 0.9617, 0.9881, 0.9515, 0.9949, 0.9857, 0.8110,\n",
      "         0.9579, 0.7052, 0.9531, 0.7202, 0.9990, 0.6352, 0.9057, 0.9213, 0.9825,\n",
      "         0.7376, 0.9699, 0.9897, 0.9718, 0.9799, 0.9684, 0.9949, 0.9789],\n",
      "        [0.9854, 0.9606, 0.9875, 0.9628, 0.9881, 0.9749, 0.9949, 0.9891, 0.8109,\n",
      "         0.9589, 0.6935, 0.9530, 0.7201, 0.9989, 0.6352, 0.9055, 0.9213, 0.9825,\n",
      "         0.7376, 0.9696, 0.9922, 0.9718, 0.9800, 0.9684, 0.9949, 0.9789],\n",
      "        [0.9857, 0.9605, 0.9878, 0.9628, 0.9881, 0.9741, 0.9950, 0.9856, 0.8227,\n",
      "         0.9585, 0.6934, 0.9528, 0.7200, 0.9991, 0.6352, 0.8910, 0.9213, 0.9825,\n",
      "         0.7375, 0.9846, 0.9922, 0.9718, 0.9800, 0.9717, 0.9950, 0.9788]])\n",
      "tensor([1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][0])\n",
    "print(dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## network 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.linear(hidden_size, output_size,)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs, _ = self.lstm(x)\n",
    "        #out : batch x timesteps x output_size\n",
    "        out = self.fc(out[: -1, :])\n",
    "        return torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyper-parameter 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch x timesteps x input_size -> ? x 9 x 26\n",
    "input_size  = 26\n",
    "hidden_size = 128\n",
    "output_size = 4\n",
    "learning_rate = 0.001 \n",
    "batch_size = 4\n",
    "\n",
    "epoch_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## criterian && optimizer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LSTM(input_size, hidden_size, output_size)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model, train_loader, num_epochs, criterion, optimizer):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    if(epoch % 100 == 0):\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}], Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, criterion, threshold):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()\n",
    "\n",
    "    accuracy = 0.0\n",
    "    precision = 0.0\n",
    "    recall = 0.0\n",
    "    f1 = 0.0\n",
    "\n",
    "    test_loss = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "\n",
    "\n",
    "    # 다중 레이블 분류 평가 지표 계산, macro : 각 클래스에 대해 개별적으로 평가\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions, average='macro')\n",
    "    recall = recall_score(true_labels, predictions, average='macro')\n",
    "    f1 = f1_score(true_labels, predictions, average='macro')\n",
    "\n",
    "    print(f'Average Test Loss: {avg_loss:.4f}')\n",
    "    print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9854827121246421,\n",
       " 0.920604914933838,\n",
       " 0.9875910236147845,\n",
       " 0.9614620372307048,\n",
       " 0.9881225954710944,\n",
       " 0.9740866046403633,\n",
       " 0.9948452268533359,\n",
       " 0.9855752728770509,\n",
       " 0.8108682923469033,\n",
       " 0.9170487349295282,\n",
       " 0.7052079064617098,\n",
       " 0.9759499409069567,\n",
       " 0.7198996276802951,\n",
       " 0.9997064038501393,\n",
       " 0.6218969393842055,\n",
       " 0.8909792391950413,\n",
       " 0.9188043028547785,\n",
       " 0.9825343018563357,\n",
       " 0.7371728076491344,\n",
       " 0.9852939638311007,\n",
       " 0.9922540327168653,\n",
       " 0.9718444744676525,\n",
       " 0.9823750385948061,\n",
       " 0.9717275959609485,\n",
       " 0.992447090747254,\n",
       " 0.9788218606370539]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = all_subject_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_video = all_subject_data[0]\n",
    "video_len = len(each_video)\n",
    "total_frame_features_list = []\n",
    "total_frame_label_list = []\n",
    "\n",
    "t_trimmed_data = []\n",
    "t_trimmed_label = []\n",
    "for idx in range(0, video_len):\n",
    "    total_frame_features_list.append(each_video[idx][0])\n",
    "    total_frame_label_list.append(each_video[idx][1])\n",
    "    \n",
    "    \n",
    "for idx in range(0, len(total_frame_features_list) - 8):\n",
    "    t_trimmed_data.append(total_frame_features_list[idx:idx + 9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data = []\n",
    "for idx in range(0, len(total_frame_features_list) - 8):\n",
    "    t_data.append(total_frame_features_list[idx:idx + 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1055"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t_trimmed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98548271, 0.92060491, 0.98759102, 0.96146204, 0.9881226 ,\n",
       "        0.9740866 , 0.99484523, 0.98557527, 0.81086829, 0.91704873,\n",
       "        0.70520791, 0.97594994, 0.71989963, 0.9997064 , 0.62189694,\n",
       "        0.89097924, 0.9188043 , 0.9825343 , 0.73717281, 0.98529396,\n",
       "        0.99225403, 0.97184447, 0.98237504, 0.9717276 , 0.99244709,\n",
       "        0.97882186],\n",
       "       [0.98563035, 0.95936408, 0.98771679, 0.96165813, 0.98816563,\n",
       "        0.97402027, 0.99489721, 0.9855716 , 0.81091135, 0.91741665,\n",
       "        0.70516431, 0.95371315, 0.71994492, 0.99957975, 0.63497453,\n",
       "        0.90563174, 0.92120914, 0.98594924, 0.73730697, 0.98518937,\n",
       "        0.98968955, 0.97188273, 0.97990497, 0.97173477, 0.99492728,\n",
       "        0.97883029],\n",
       "       [0.98572877, 0.92044172, 0.98767487, 0.9613836 , 0.9881226 ,\n",
       "        0.97385442, 0.99487122, 0.98558631, 0.82275091, 0.91665252,\n",
       "        0.70520791, 0.95289556, 0.71999022, 0.99959702, 0.63502042,\n",
       "        0.90579095, 0.92121776, 0.9859887 , 0.73735169, 0.98525213,\n",
       "        0.99218401, 0.97179785, 0.97994785, 0.97167499, 0.99245573,\n",
       "        0.97885076],\n",
       "       [0.98567956, 0.92074091, 0.98775871, 0.96161891, 0.98807956,\n",
       "        0.97416953, 0.9949232 , 0.98557527, 0.82275091, 0.91686478,\n",
       "        0.7052515 , 0.95313031, 0.72003551, 0.99982154, 0.63483687,\n",
       "        0.90561051, 0.91883878, 0.98597316, 0.73748586, 0.99993724,\n",
       "        0.98961078, 0.97183013, 0.97985351, 0.97166662, 0.99496185,\n",
       "        0.97882066],\n",
       "       [0.98563035, 0.92016972, 0.98767487, 0.96106986, 0.98816563,\n",
       "        0.97426903, 0.99488854, 0.98562921, 0.82270786, 0.91646856,\n",
       "        0.70516431, 0.9531465 , 0.71999022, 0.99971216, 0.63488276,\n",
       "        0.90556275, 0.91883878, 0.98594805, 0.73739641, 0.99979081,\n",
       "        0.98961953, 0.97175959, 0.97987066, 0.96836331, 0.99491864,\n",
       "        0.97885798],\n",
       "       [0.98563035, 0.92019692, 0.98767487, 0.9611483 , 0.9881226 ,\n",
       "        0.97388759, 0.99487988, 0.98565005, 0.81099745, 0.91676572,\n",
       "        0.70512072, 0.95289556, 0.72008081, 0.99943008, 0.63502042,\n",
       "        0.89096863, 0.92122638, 0.9825355 , 0.7375753 , 0.98493311,\n",
       "        0.98961078, 0.96839632, 0.97987924, 0.96827723, 0.99490135,\n",
       "        0.97889411],\n",
       "       [0.98567956, 0.95951367, 0.98771679, 0.96173656, 0.9881226 ,\n",
       "        0.95154817, 0.99490587, 0.98565618, 0.8110405 , 0.95790174,\n",
       "        0.70520791, 0.95313841, 0.72017139, 0.99904437, 0.63515808,\n",
       "        0.90568481, 0.92125224, 0.98254387, 0.73762002, 0.96987145,\n",
       "        0.98965454, 0.97176198, 0.97992212, 0.96838364, 0.99492728,\n",
       "        0.97890374],\n",
       "       [0.9854335 , 0.96061525, 0.98746526, 0.96282159, 0.98807956,\n",
       "        0.97489925, 0.99490587, 0.98910208, 0.81091135, 0.95889229,\n",
       "        0.69348074, 0.9529927 , 0.72008081, 0.9988947 , 0.63520396,\n",
       "        0.9055256 , 0.92125224, 0.98248169, 0.7375753 , 0.96957336,\n",
       "        0.99219277, 0.9717548 , 0.97995643, 0.96839798, 0.99491864,\n",
       "        0.97891458],\n",
       "       [0.98567956, 0.96047925, 0.98775871, 0.9627693 , 0.9881226 ,\n",
       "        0.97410319, 0.99495785, 0.98559366, 0.82270786, 0.95851022,\n",
       "        0.69343715, 0.95279032, 0.72003551, 0.99911921, 0.63524985,\n",
       "        0.89098455, 0.92125224, 0.98249604, 0.73748586, 0.98461933,\n",
       "        0.99221902, 0.97179306, 0.97996501, 0.97165586, 0.99497049,\n",
       "        0.97882306]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(t_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
